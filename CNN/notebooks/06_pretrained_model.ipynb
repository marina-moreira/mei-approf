{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"background-color:#C2B4B9;color:white;text-align: center;padding-top: 5px;padding-bottom: 5px;border-radius: 15px 50px;\"><strong><centre>Bird Species Classification Using Convolutional Neural Networks </centre></strong></h1>\n",
    "<img src=\"../images/logo_part1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color:#C2B4B9;color:white;text-align: center;padding-top: 5px;padding-bottom: 5px;border-radius: 15px 50px;\"><strong><centre>Methodology: Model Architecture </centre></strong></h2>\n",
    "\n",
    "#### 03.Model Development\n",
    "##### Convolutional Neural Networks (CNN) for Bird Species Classification\n",
    "\n",
    "##### Building a baseline ResNet-50 classifier\n",
    "\n",
    "We are going to use ResNet-50 model for classification of bird species. ResNet (stands for Residual Networks) is a variant of convolutional neural networks that was [proposed](https://arxiv.org/abs/1512.03385, 'He et. al, 2015') as a solution to the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem) of large networks by using the skip or residual connections. \n",
    "PyTorch provides the ResNet-50 among the other ready-to-use deep learning models on `torchvision.models`, so we'll instantiate the respective class. Given the dataset of 200 bird species, we will set the argument *num_classes* to that number, and also define the device on which to run the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "#### Import Libraries:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:47:50.416657Z",
     "start_time": "2024-06-02T23:47:47.437089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Load and Preprocess Data:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:49:34.477389Z",
     "start_time": "2024-06-02T23:49:34.376886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = '../dataset/raw/CUB_200_2011/images/'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1176 images belonging to 25 classes.\n",
      "Found 290 images belonging to 25 classes.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Define Pretrained Model (ResNet50):"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T23:56:21.005661Z",
     "start_time": "2024-06-02T23:56:19.960048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3)) #NÃO DEVIA ESTAR AQUI DEFINIDO O PATH PARA GUARDAR O MODELO? \n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "model_ResNet50 = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "model_ResNet50.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Train Model:"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T00:06:57.569255Z",
     "start_time": "2024-06-02T23:56:26.512113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_ResNet50 = model_ResNet50.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "model_ResNet50.save('models/pretrained/resnet50_bird_species_model.h5')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 2s/step - accuracy: 0.0636 - loss: 3.5741 - val_accuracy: 0.0241 - val_loss: 3.2213\n",
      "Epoch 2/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m63s\u001B[0m 2s/step - accuracy: 0.0308 - loss: 3.4044 - val_accuracy: 0.0586 - val_loss: 3.2101\n",
      "Epoch 3/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m60s\u001B[0m 2s/step - accuracy: 0.0370 - loss: 3.3678 - val_accuracy: 0.0621 - val_loss: 3.2116\n",
      "Epoch 4/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 2s/step - accuracy: 0.0643 - loss: 3.2827 - val_accuracy: 0.0310 - val_loss: 3.2070\n",
      "Epoch 5/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m64s\u001B[0m 2s/step - accuracy: 0.0605 - loss: 3.2694 - val_accuracy: 0.0552 - val_loss: 3.2015\n",
      "Epoch 6/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m63s\u001B[0m 2s/step - accuracy: 0.0368 - loss: 3.2517 - val_accuracy: 0.0345 - val_loss: 3.1976\n",
      "Epoch 7/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 2s/step - accuracy: 0.0406 - loss: 3.2413 - val_accuracy: 0.0655 - val_loss: 3.1939\n",
      "Epoch 8/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 2s/step - accuracy: 0.0429 - loss: 3.2250 - val_accuracy: 0.0621 - val_loss: 3.1859\n",
      "Epoch 9/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m62s\u001B[0m 2s/step - accuracy: 0.0435 - loss: 3.2343 - val_accuracy: 0.0793 - val_loss: 3.1904\n",
      "Epoch 10/10\n",
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m61s\u001B[0m 2s/step - accuracy: 0.0569 - loss: 3.2030 - val_accuracy: 0.0552 - val_loss: 3.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot Training History:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "acc = history_ResNet50.history['accuracy']\n",
    "val_acc = history_ResNet50.history['val_accuracy']\n",
    "loss = history_ResNet50.history['loss']\n",
    "val_loss = history_ResNet50.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Evaluate Model:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "val_loss, val_acc = model_ResNet50.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_acc:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
